import whisper
import os
from pyannote.audio.pipelines import SpeakerDiarization
from pyannote.core import Segment
from google.colab import files

# Hugging Face Token 입력 (화자분리를 위한)
HUGGINGFACE_TOKEN = "이건 비밀"

# 회의 음성 파일 업로드
uploaded = files.upload()
audio_file = list(uploaded.keys())[0]

# Whisper STT 실행
model = whisper.load_model("medium")
result = model.transcribe(audio_file, verbose=False)
segments = result["segments"]
setting_filename = os.path.splitext(audio_file)[0]

# Pyannote 화자 분리 실행
pipeline = SpeakerDiarization.from_pretrained("pyannote/speaker-diarization", use_auth_token=HUGGINGFACE_TOKEN)
diarization = pipeline(audio_file)

# 회의록 매핑 함수

# 회의록 타임 스탬프 표시
def format_timestamp(start, end):
    return f"[{int(start//60):02d}:{int(start%60):02d} → {int(end//60):02d}:{int(end%60):02d}]"

def generate_speaker_transcript(segments, diarization, output_file):
    with open(output_file, "w", encoding="utf-8") as f:
        for segment in segments:
            mid = (segment["start"] + segment["end"]) / 2
            speaker_label = "Unknown"
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                if turn.start <= mid <= turn.end:
                    speaker_label = speaker
                    break
            timestamp = format_timestamp(segment["start"], segment["end"])
            text = segment["text"].strip()
            line = f"{timestamp} ({speaker_label}): {text}"
            print(line)
            f.write(line + "\n")
    print(f"\n 화자 매핑 회의록 저장 완료 {output_file}")

# 실행
output_path = f"{setting_filename}_final_transcript.txt"
generate_speaker_transcript(segments, diarization, output_path)

# 코랩에서 다운로드
from google.colab import files
files.download(output_path)


